# YOLOv5 PyTorch utils
# è¿™ä¸ªæ–‡ä»¶ä¸»è¦æ˜¯åŸºäºtorchçš„ä¸€äº›å®ç”¨å·¥å…·ç±»

import datetime    # æ—¶é—´æ¨¡å—  åŸºäºtimeè¿›è¡Œäº†å°è£… æ›´é«˜çº§
import logging     # æ—¥å¿—åŠŸèƒ½ç”Ÿæˆæ¨¡å—
import math        # æ•°å­¦å‡½æ•°æ¨¡å—
import os          # ä¸æ“ä½œç³»ç»Ÿè¿›è¡Œäº¤äº’çš„æ¨¡å—
import platform    # æä¾›è·å–æ“ä½œç³»ç»Ÿç›¸å…³ä¿¡æ¯çš„æ¨¡å—
import subprocess  # å­è¿›ç¨‹å®šä¹‰åŠæ“ä½œçš„æ¨¡å—
import time        # æ—¶é—´æ¨¡å— æ›´åº•å±‚
from contextlib import contextmanager  # ç”¨äºè¿›è¡Œä¸Šä¸‹æ–‡ç®¡ç†çš„æ¨¡å—
from copy import deepcopy  # å®ç°æ·±åº¦å¤åˆ¶çš„æ¨¡å—
from pathlib import Path   # Pathå°†strè½¬æ¢ä¸ºPathå¯¹è±¡ ä½¿å­—ç¬¦ä¸²è·¯å¾„æ˜“äºæ“ä½œçš„æ¨¡å—

# ä»¥ä¸‹æ˜¯ä¸€äº›åŸºæœ¬çš„torchç›¸å…³çš„ç±»
import torch
import torch.backends.cudnn as cudnn
import torch.distributed as dist
import torch.nn as nn
import torch.nn.functional as F
import torchvision

try:
    import thop  # ç”¨äºPytorchæ¨¡å‹çš„FLOPSè®¡ç®—å·¥å…·æ¨¡å—
except ImportError:
    thop = None
logger = logging.getLogger(__name__)  # åˆå§‹åŒ–æ—¥å¿—

@contextmanager
def torch_distributed_zero_first(local_rank: int):
    """ç”¨åœ¨train.py
    ç”¨äºå¤„ç†æ¨¡å‹è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒæ—¶åŒæ­¥é—®é¢˜
    åŸºäºtorch.distributed.barrier()å‡½æ•°çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä¸ºäº†å®Œæˆæ•°æ®çš„æ­£å¸¸åŒæ­¥æ“ä½œï¼ˆyolov5ä¸­æ‹¥æœ‰å¤§é‡çš„å¤šçº¿ç¨‹å¹¶è¡Œæ“ä½œï¼‰
    Decorator to make all processes in distributed training wait for each local_master to do something.
    :params local_rank: ä»£è¡¨å½“å‰è¿›ç¨‹å·  0ä»£è¡¨ä¸»è¿›ç¨‹  1ã€2ã€3ä»£è¡¨å­è¿›ç¨‹
    """
    if local_rank not in [-1, 0]:
        # å¦‚æœæ‰§è¡Œcreate_dataloader()å‡½æ•°çš„è¿›ç¨‹ä¸æ˜¯ä¸»è¿›ç¨‹ï¼Œå³rankä¸ç­‰äº0æˆ–è€…-1ï¼Œ
        # ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šæ‰§è¡Œç›¸åº”çš„torch.distributed.barrier()ï¼Œè®¾ç½®ä¸€ä¸ªé˜»å¡æ …æ ï¼Œ
        # è®©æ­¤è¿›ç¨‹å¤„äºç­‰å¾…çŠ¶æ€ï¼Œç­‰å¾…æ‰€æœ‰è¿›ç¨‹åˆ°è¾¾æ …æ å¤„ï¼ˆåŒ…æ‹¬ä¸»è¿›ç¨‹æ•°æ®å¤„ç†å®Œæ¯•ï¼‰ï¼›
        dist.barrier()
    yield  # yieldè¯­å¥ ä¸­æ–­åæ‰§è¡Œä¸Šä¸‹æ–‡ä»£ç ï¼Œç„¶åè¿”å›åˆ°æ­¤å¤„ç»§ç»­å¾€ä¸‹æ‰§è¡Œ
    if local_rank == 0:
        # å¦‚æœæ‰§è¡Œcreate_dataloader()å‡½æ•°çš„è¿›ç¨‹æ˜¯ä¸»è¿›ç¨‹ï¼Œå…¶ä¼šç›´æ¥å»è¯»å–æ•°æ®å¹¶å¤„ç†ï¼Œ
        # ç„¶åå…¶å¤„ç†ç»“æŸä¹‹åä¼šæ¥ç€é‡åˆ°torch.distributed.barrier()ï¼Œ
        # æ­¤æ—¶ï¼Œæ‰€æœ‰è¿›ç¨‹éƒ½åˆ°è¾¾äº†å½“å‰çš„æ …æ å¤„ï¼Œè¿™æ ·æ‰€æœ‰è¿›ç¨‹å°±è¾¾åˆ°äº†åŒæ­¥ï¼Œå¹¶åŒæ—¶å¾—åˆ°é‡Šæ”¾ã€‚
        dist.barrier()

def init_torch_seeds(seed=0):
    """ç”¨åœ¨general.pyçš„init_seedså‡½æ•°
    ç”¨äºåˆå§‹åŒ–éšæœºç§å­å¹¶ç¡®å®šè®­ç»ƒæ¨¡å¼
    Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html
    """
    # ä¸ºCPUè®¾ç½®éšæœºç§å­ï¼Œæ–¹ä¾¿ä¸‹æ¬¡å¤ç°å®éªŒç»“æœ  to seed the RNG for all devices (both CPU and CUDA)
    torch.manual_seed(seed)
    # benchmarkæ¨¡å¼ä¼šè‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜é…ç½® ä½†ç”±äºè®¡ç®—çš„éšæœºæ€§ æ¯æ¬¡ç½‘ç»œè¿›è¡Œå‰å‘ä¼ æ’­æ—¶ä¼šæœ‰å·®å¼‚
    # é¿å…è¿™ç§å·®å¼‚çš„æ–¹æ³•å°±æ˜¯å°†deterministicè®¾ç½®ä¸ºTrue(è¡¨æ˜æ¯æ¬¡å·ç§¯çš„é«˜æ•ˆç®—æ³•ç›¸åŒ)
    # é€Ÿåº¦ä¸å¯é‡å¤æ€§ä¹‹é—´çš„æƒè¡¡  æ¶‰åŠåº•å±‚å·ç§¯ç®—æ³•ä¼˜åŒ–
    if seed == 0:
        # slower, more reproducible  æ…¢ ä½†æ˜¯å…·æœ‰å¯é‡å¤æ€§ é€‚ç”¨äºç½‘ç»œçš„è¾“å…¥æ•°æ®åœ¨æ¯æ¬¡iterationéƒ½å˜åŒ–çš„è¯
        cudnn.benchmark, cudnn.deterministic = False, True
    else:
        # faster, less reproducible å¿« ä½†æ˜¯ä¸å¯é‡å¤  é€‚ç”¨äºç½‘ç»œçš„è¾“å…¥æ•°æ®ç»´åº¦æˆ–ç±»å‹ä¸Šå˜åŒ–ä¸å¤§
        cudnn.benchmark, cudnn.deterministic = True, False

def git_describe(path=Path(__file__).parent):
    """ç”¨åœ¨select_device
    ç”¨äºè¿”å›pathæ–‡ä»¶å¯è¯»çš„gitæè¿°  return human-readable git description  i.e. v5.0-5-g3e25f1e
    https://git-scm.com/docs/git-describe
    path: éœ€è¦åœ¨gitä¸­æŸ¥è¯¢ï¼ˆæ–‡ä»¶æè¿°ï¼‰çš„æ–‡ä»¶å  é»˜è®¤å½“å‰æ–‡ä»¶çš„çˆ¶è·¯å¾„
    """
    # path must be a directory
    s = f'git -C {path} describe --tags --long --always'
    try:
        # åˆ›å»ºä¸€ä¸ªå­è¿›ç¨‹åœ¨å‘½ä»¤è¡Œæ‰§è¡Œ s(git) å‘½ä»¤(è¿”å›pathæ–‡ä»¶çš„æè¿°) è¿”å›æ‰§è¡Œç»“æœ(pathæ–‡ä»¶çš„æè¿°)
        return subprocess.check_output(s, shell=True, stderr=subprocess.STDOUT).decode()[:-1]
    except subprocess.CalledProcessError as e:
        # å‘ç”Ÿå¼‚å¸¸ path not a git repository è¿”å›''
        return ''
def date_modified(path=__file__):
    """ç”¨åœ¨select_device
    è¿”å›pathæ–‡ä»¶äººç±»å¯è¯»çš„ä¿®æ”¹æ—¥æœŸ
    return human-readable file modification date, i.e. '2021-3-26'
    :params path: æ–‡ä»¶å é»˜è®¤å½“å‰æ–‡ä»¶
    """
    t = datetime.datetime.fromtimestamp(Path(path).stat().st_mtime)
    return f'{t.year}-{t.month}-{t.day}'
def select_device(device='', batch_size=None):
    """å¹¿æ³›ç”¨äºtrain.pyã€val.pyã€detect.pyç­‰æ–‡ä»¶ä¸­
    ç”¨äºé€‰æ‹©æ¨¡å‹è®­ç»ƒçš„è®¾å¤‡ å¹¶è¾“å‡ºæ—¥å¿—ä¿¡æ¯
    :params device: è¾“å…¥çš„è®¾å¤‡  device = 'cpu' or '0' or '0,1,2,3'
    :params batch_size: ä¸€ä¸ªæ‰¹æ¬¡çš„å›¾ç‰‡ä¸ªæ•°
    """
    # git_describe(): è¿”å›å½“å‰æ–‡ä»¶çˆ¶æ–‡ä»¶çš„æè¿°ä¿¡æ¯(yolov5)   date_modified(): è¿”å›å½“å‰æ–‡ä»¶çš„ä¿®æ”¹æ—¥æœŸ
    # s: ä¹‹åè¦åŠ å…¥loggeræ—¥å¿—çš„æ˜¾ç¤ºä¿¡æ¯
    s = f'YOLOv5 ğŸš€ {git_describe() or date_modified()} torch {torch.__version__} '  # string

    # å¦‚æœdeviceè¾“å…¥ä¸ºcpu  cpu=True  device.lower(): å°†deviceå­—ç¬¦ä¸²å…¨éƒ¨è½¬ä¸ºå°å†™å­—æ¯
    cpu = device.lower() == 'cpu'
    if cpu:
        # å¦‚æœcpu=True å°±å¼ºåˆ¶(force)ä½¿ç”¨cpu ä»¤torch.cuda.is_available() = False
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    elif device:
        # å¦‚æœè¾“å…¥deviceä¸ä¸ºç©º  device=GPU  ç›´æ¥è®¾ç½® CUDA environment variable = device åŠ å…¥CUDAå¯ç”¨è®¾å¤‡
        os.environ['CUDA_VISIBLE_DEVICES'] = device
        # æ£€æŸ¥cudaçš„å¯ç”¨æ€§ å¦‚æœä¸å¯ç”¨åˆ™ç»ˆæ­¢ç¨‹åº
        assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'

    # è¾“å…¥deviceä¸ºç©º è‡ªè¡Œæ ¹æ®è®¡ç®—æœºæƒ…å†µé€‰æ‹©ç›¸åº”è®¾å¤‡  å…ˆçœ‹GPU æ²¡æœ‰å°±CPU
    # å¦‚æœcudaå¯ç”¨ ä¸” è¾“å…¥device != cpu åˆ™ cuda=True åæ­£cuda=False
    cuda = not cpu and torch.cuda.is_available()
    if cuda:
        # devices: å¦‚æœcudaå¯ç”¨ è¿”å›æ‰€æœ‰å¯ç”¨çš„gpuè®¾å¤‡ i.e. 0,1,6,7  å¦‚æœä¸å¯ç”¨å°±è¿”å› '0'
        devices = device.split(',') if device else '0'
        # n: æ‰€æœ‰å¯ç”¨çš„gpuè®¾å¤‡æ•°é‡  device count
        n = len(devices)
        # æ£€æŸ¥æ˜¯å¦æœ‰gpuè®¾å¤‡ ä¸” batch_sizeæ˜¯å¦å¯ä»¥èƒ½è¢«æ˜¾å¡æ•°ç›®æ•´é™¤  check batch_size is divisible by device_count
        if n > 1 and batch_size:
            # å¦‚æœä¸èƒ½åˆ™å…³é—­ç¨‹åº
            assert batch_size % n == 0, f'batch-size {batch_size} not multiple of GPU count {n}'

        space = ' ' * (len(s) + 1)   # å®šä¹‰ç­‰é•¿çš„ç©ºæ ¼

        # æ»¡è¶³æ‰€æœ‰æ¡ä»¶ såŠ ä¸Šæ‰€æœ‰æ˜¾å¡çš„ä¿¡æ¯
        for i, d in enumerate(devices):
            # p: æ¯ä¸ªå¯ç”¨æ˜¾å¡çš„ç›¸å…³å±æ€§
            p = torch.cuda.get_device_properties(i)
            # æ˜¾ç¤ºä¿¡æ¯såŠ ä¸Šæ¯å¼ æ˜¾å¡çš„å±æ€§ä¿¡æ¯
            s += f"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / 1024 ** 2}MB)\n"  # bytes to MB
    else:
        # cudaä¸å¯ç”¨æ˜¾ç¤ºä¿¡æ¯så°±åŠ ä¸ŠCPU
        s += 'CPU\n'

    # å°†æ˜¾ç¤ºä¿¡æ¯såŠ å…¥loggeræ—¥å¿—æ–‡ä»¶ä¸­
    logger.info(s.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else s)  # emoji-safe
    # å¦‚æœcudaå¯ç”¨å°±è¿”å›ç¬¬ä¸€å¼ æ˜¾å¡çš„çš„åç§° å¦‚: GeForce RTX 2060 åä¹‹è¿”å›CPUå¯¹åº”çš„åç§°
    return torch.device('cuda:0' if cuda else 'cpu')

def intersect_dicts(da, db, exclude=()):
    """ç”¨äºtrain.pyä¸­è½½å…¥é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œç­›é€‰é¢„è®­ç»ƒæƒé‡ä¸­çš„é”®å€¼å¯¹
    ç”¨äºç­›é€‰å­—å…¸ä¸­çš„é”®å€¼å¯¹  å°†dbä¸­çš„é”®å€¼å¯¹å¤åˆ¶ç»™da,ä½†æ˜¯é™¤äº†excludeä¸­çš„é”®å€¼å¯¹
    """
    # è¿”å›å­—å…¸daä¸­çš„é”®å€¼å¯¹  è¦æ±‚é”®kåœ¨å­—å…¸dbä¸­ä¸”å…¨éƒ¨éƒ½ä¸åœ¨excludeä¸­ åŒæ—¶daä¸­å€¼çš„shapeå¯¹åº”dbä¸­å€¼çš„shape(ç›¸åŒ)
    return {k: v for k, v in da.items() if k in db
            and not any(x in k for x in exclude) and v.shape == db[k].shape}

def time_synchronized():
    """è¿™ä¸ªå‡½æ•°è¢«å¹¿æ³›çš„ç”¨äºæ•´ä¸ªé¡¹ç›®çš„å„ä¸ªæ–‡ä»¶ä¸­ï¼Œåªè¦æ¶‰åŠè·å–å½“å‰æ—¶é—´çš„æ“ä½œï¼Œå°±éœ€è¦è°ƒç”¨è¿™ä¸ªå‡½æ•°
    ç²¾ç¡®è®¡ç®—å½“å‰æ—¶é—´  å¹¶è¿”å›å½“å‰æ—¶é—´
    https://blog.csdn.net/qq_23981335/article/details/105709273
    pytorch-accurate time
    å…ˆè¿›è¡Œtorch.cuda.synchronize()æ·»åŠ åŒæ­¥æ“ä½œ å†è¿”å›time.time()å½“å‰æ—¶é—´
    ä¸ºä»€ä¹ˆä¸ç›´æ¥ä½¿ç”¨time.time()å–æ—¶é—´ï¼Œè€Œè¦å…ˆæ‰§è¡ŒåŒæ­¥æ“ä½œï¼Œå†å–æ—¶é—´ï¼Ÿè¯´ä¸€ä¸‹è¿™æ ·å­åšçš„åŸå› :
       åœ¨pytorché‡Œé¢ï¼Œç¨‹åºçš„æ‰§è¡Œéƒ½æ˜¯å¼‚æ­¥çš„ã€‚
       å¦‚æœtime.time(), æµ‹è¯•çš„æ—¶é—´ä¼šå¾ˆçŸ­ï¼Œå› ä¸ºæ‰§è¡Œå®Œend=time.time()ç¨‹åºå°±é€€å‡ºäº†
       è€Œå…ˆåŠ torch.cuda.synchronize()ä¼šå…ˆåŒæ­¥cudaçš„æ“ä½œï¼Œç­‰å¾…gpuä¸Šçš„æ“ä½œéƒ½å®Œæˆäº†å†ç»§ç»­è¿è¡Œend = time.time()
       è¿™æ ·å­æµ‹è¯•æ—¶é—´ä¼šå‡†ç¡®ä¸€ç‚¹
    """
    if torch.cuda.is_available():
        torch.cuda.synchronize()
    return time.time()

# æ²¡ç”¨åˆ°
def profile(x, ops, n=100, device=None):
    """
    è¾“å‡ºæŸä¸ªç½‘ç»œç»“æ„(æ“ä½œops)çš„ä¸€äº›ä¿¡æ¯: æ€»å‚æ•° æµ®ç‚¹è®¡ç®—é‡ å‰å‘ä¼ æ’­æ—¶é—´ åå‘ä¼ æ’­æ—¶é—´ è¾“å…¥å˜é‡çš„shape è¾“å‡ºå˜é‡çš„shape
    :params x: è¾“å…¥tensor x
    :params ops: æ“ä½œops(æŸä¸ªç½‘ç»œç»“æ„)
    :params n: æ‰§è¡Œå¤šå°‘è½®ops
    :params device: æ‰§è¡Œè®¾å¤‡
    """
    # profile a pytorch module or list of modules. Example usage:
    #     x = torch.randn(16, 3, 640, 640)  # input
    #     m1 = lambda x: x * torch.sigmoid(x)
    #     m2 = nn.SiLU()
    #     profile(x, [m1, m2], n=100)  # profile speed over 100 iterations

    # é€‰æ‹©è®¾å¤‡
    device = device or torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    # å°†xå˜é‡é€å…¥é€‰æ‹©çš„è®¾å¤‡ä¸Š
    x = x.to(device)
    # è¡¨æ˜éœ€è¦è®¡ç®—tensor xçš„æ¢¯åº¦
    x.requires_grad = True
    # æ‰“å°å½“å‰è®¾å¤‡çš„ä¿¡æ¯ æµ®ç‚¹è®¡ç®—é‡GFLOPs å‰å‘ä¼ æ’­æ—¶é—´ åå‘ä¼ æ’­æ—¶é—´ è¾“å…¥ç›¸å…³æ—¶é—´ è¾“å‡ºç›¸å…³æ—¶é—´
    print(torch.__version__, device.type, torch.cuda.get_device_properties(0) if device.type == 'cuda' else '')
    print(f"\n{'Params':>12s}{'GFLOPs':>12s}{'forward (ms)':>16s}{'backward (ms)':>16s}{'input':>24s}{'output':>24s}")

    for m in ops if isinstance(ops, list) else [ops]:
        # ç¡®ä¿opsä¸­æ‰€æœ‰çš„æ“ä½œéƒ½æ˜¯åœ¨deviceè®¾å¤‡ä¸­è¿è¡Œ
        # hasattr(m, 'to'): åˆ¤æ–­å¯¹è±¡mæ²¡æœ‰toå±æ€§
        m = m.to(device) if hasattr(m, 'to') else m  # device
        # ç¡®ä¿æ“ä½œmå’Œtensor xæ˜¯å¤„äºç›¸åŒçš„ç²¾åº¦  é»˜è®¤xæ˜¯Float32çš„  halfå¯ä»¥å°†ç²¾åº¦å‡åŠ
        m = m.half() if hasattr(m, 'half') and isinstance(x, torch.Tensor) and x.dtype is torch.float16 else m  # type
        # åˆå§‹åŒ–å‰å‘ä¼ æ’­æ—¶é—´dtf åå‘ä¼ æ’­æ—¶é—´dtb ä»¥åŠtå˜é‡ç”¨äºè®°å½•ä¸‰ä¸ªæ—¶åˆ»çš„æ—¶é—´(åé¢æœ‰å†™)
        dtf, dtb, t = 0., 0., [0., 0., 0.]  # dt forward, backward
        try:
            # è®¡ç®—åœ¨è¾“å…¥ä¸ºtensor x, æ“ä½œä¸ºmæ¡ä»¶ä¸‹çš„æµ®ç‚¹è®¡ç®—é‡GFLOPs
            flops = thop.profile(m, inputs=(x,), verbose=False)[0] / 1E9 * 2
        except:
            flops = 0

        for _ in range(n):  # æ‰§è¡Œ100æ¬¡ ç®—å¹³å‡ æ›´å‡†ç¡®
            t[0] = time_synchronized()     # æ“ä½œmå‰å‘ä¼ æ’­å‰ä¸€æ—¶åˆ»çš„æ—¶é—´
            y = m(x)                       # æ“ä½œmå‰å‘ä¼ æ’­
            t[1] = time_synchronized()     # æ“ä½œmå‰å‘ä¼ æ’­åä¸€æ—¶åˆ»çš„æ—¶é—´ = æ“ä½œmåå‘ä¼ æ’­å‰ä¸€æ—¶åˆ»çš„æ—¶é—´
            try:
                _ = y.sum().backward()     # æ“ä½œmåå‘ä¼ æ’­
                t[2] = time_synchronized() # æ“ä½œmåå‘ä¼ æ’­åä¸€æ—¶åˆ»çš„æ—¶é—´
            except:  # å¦‚æœæ²¡æœ‰åå‘ä¼ æ’­
                t[2] = float('nan')
            dtf += (t[1] - t[0]) * 1000 / n  # æ“ä½œmå¹³å‡æ¯æ¬¡å‰å‘ä¼ æ’­æ‰€ç”¨æ—¶é—´
            dtb += (t[2] - t[1]) * 1000 / n  # æ“ä½œmå¹³å‡æ¯æ¬¡åå‘ä¼ æ’­æ‰€ç”¨æ—¶é—´

        # s_in: è¾“å…¥å˜é‡çš„shape
        s_in = tuple(x.shape) if isinstance(x, torch.Tensor) else 'list'
        # s_out: è¾“å‡ºå˜é‡çš„shape
        s_out = tuple(y.shape) if isinstance(y, torch.Tensor) else 'list'
        # p: mæ“ä½œ(æŸä¸ªç½‘ç»œç»“æ„)çš„æ€»å‚æ•°  parameters
        p = sum(list(x.numel() for x in m.parameters())) if isinstance(m, nn.Module) else 0

        # è¾“å‡ºæ¯ä¸ªæ“ä½œ(æŸä¸ªç½‘ç»œç»“æ„)çš„ä¿¡æ¯: æ€»å‚æ•° æµ®ç‚¹è®¡ç®—é‡ å‰å‘ä¼ æ’­æ—¶é—´ åå‘ä¼ æ’­æ—¶é—´ è¾“å…¥å˜é‡çš„shape è¾“å‡ºå˜é‡çš„shape
        print(f'{p:12}{flops:12.4g}{dtf:16.4g}{dtb:16.4g}{str(s_in):>24s}{str(s_out):>24s}')
def model_info(model, verbose=False, img_size=640):
    """ç”¨äºyolo.pyæ–‡ä»¶çš„Modelç±»çš„infoå‡½æ•°
    è¾“å‡ºæ¨¡å‹çš„æ‰€æœ‰ä¿¡æ¯ åŒ…æ‹¬: æ‰€æœ‰å±‚æ•°é‡, æ¨¡å‹æ€»å‚æ•°é‡, éœ€è¦æ±‚æ¢¯åº¦çš„æ€»å‚æ•°é‡, img_sizeå¤§å°çš„modelçš„æµ®ç‚¹è®¡ç®—é‡GFLOPs
    :params model: æ¨¡å‹
    :params verbose: æ˜¯å¦è¾“å‡ºæ¯ä¸€å±‚çš„å‚æ•°parametersçš„ç›¸å…³ä¿¡æ¯
    :params img_size: int or list  i.e. img_size=640 or img_size=[640, 320]
    """
    # n_p: æ¨¡å‹modelçš„æ€»å‚æ•°  number parameters
    n_p = sum(x.numel() for x in model.parameters())
    # n_g: æ¨¡å‹modelçš„å‚æ•°ä¸­éœ€è¦æ±‚æ¢¯åº¦(requires_grad=True)çš„å‚æ•°é‡  number gradients
    n_g = sum(x.numel() for x in model.parameters() if x.requires_grad)
    if verbose:
        # è¡¨å¤´: 'layer', 'name',  'gradient',    'parameters',    'shape',        'mu',         'sigma'
        #       ç¬¬å‡ å±‚    å±‚å   boolæ˜¯å¦éœ€è¦æ±‚æ¢¯åº¦   å½“å‰å±‚å‚æ•°é‡   å½“å‰å±‚å‚æ•°shape  å½“å‰å±‚å‚æ•°å‡å€¼    å½“å‰å±‚å‚æ•°æ–¹å·®
        print('%5s %40s %9s %12s %20s %10s %10s' % ('layer', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))
        # æŒ‰è¡¨å¤´è¾“å‡ºæ¯ä¸€å±‚çš„å‚æ•°parametersçš„ç›¸å…³ä¿¡æ¯
        for i, (name, p) in enumerate(model.named_parameters()):
            name = name.replace('module_list.', '')
            print('%5g %40s %9s %12g %20s %10.3g %10.3g' %
                  (i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))

    try:  # FLOPs
        from thop import profile  # å¯¼å…¥è®¡ç®—æµ®ç‚¹è®¡ç®—é‡FLOPsçš„å·¥å…·åŒ…
        # stride æ¨¡å‹çš„æœ€å¤§ä¸‹é‡‡æ ·ç‡ æœ‰[8, 16, 32] æ‰€ä»¥stride=32
        stride = max(int(model.stride.max()), 32) if hasattr(model, 'stride') else 32
        # æ¨¡æ‹Ÿä¸€æ ·è¾“å…¥å›¾ç‰‡ shape=(1, 3, 32, 32)  å…¨æ˜¯0
        img = torch.zeros((1, model.yaml.get('ch', 3), stride, stride), device=next(model.parameters()).device)  # input
        # è°ƒç”¨profileè®¡ç®—è¾“å…¥å›¾ç‰‡img=(1, 3, 32, 32)æ—¶å½“å‰æ¨¡å‹çš„æµ®ç‚¹è®¡ç®—é‡GFLOPs   stride GFLOPs
        # profileæ±‚å‡ºæ¥çš„æµ®ç‚¹è®¡ç®—é‡æ˜¯FLOPs  /1E9 => GFLOPs
        # *2æ˜¯å› ä¸ºprofileå‡½æ•°é»˜è®¤æ±‚çš„å°±æ˜¯æ¨¡å‹ä¸ºfloat64æ—¶çš„æµ®ç‚¹è®¡ç®—é‡ è€Œæˆ‘ä»¬ä¼ å…¥çš„æ¨¡å‹ä¸€èˆ¬éƒ½æ˜¯float32 æ‰€ä»¥ä¹˜ä»¥2(å¯ä»¥ç‚¹è¿›profileçœ‹ä»–å®šä¹‰çš„add_hookså‡½æ•°)
        flops = profile(deepcopy(model), inputs=(img,), verbose=False)[0] / 1E9 * 2
        # expand  img_size -> [img_size, img_size]=[640, 640]
        img_size = img_size if isinstance(img_size, list) else [img_size, img_size]
        # æ ¹æ®img=(1, 3, 32, 32)çš„æµ®ç‚¹è®¡ç®—é‡flopsæ¨ç®—å‡º640x640çš„å›¾ç‰‡çš„æµ®ç‚¹è®¡ç®—é‡GFLOPs
        # ä¸ç›´æ¥è®¡ç®—640x640çš„å›¾ç‰‡çš„æµ®ç‚¹è®¡ç®—é‡GFLOPså¯èƒ½æ˜¯ä¸ºäº†é«˜æ•ˆæ€§å§, è¿™æ ·ç®—å¯èƒ½é€Ÿåº¦æ›´å¿«
        fs = ', %.1f GFLOPs' % (flops * img_size[0] / stride * img_size[1] / stride)
    except (ImportError, Exception):
        fs = ''

    # æ·»åŠ æ—¥å¿—ä¿¡æ¯
    # Model Summary: æ‰€æœ‰å±‚æ•°é‡, æ¨¡å‹æ€»å‚æ•°é‡, éœ€è¦æ±‚æ¢¯åº¦çš„æ€»å‚æ•°é‡, img_sizeå¤§å°çš„modelçš„æµ®ç‚¹è®¡ç®—é‡GFLOPs
    logger.info(f"Model Summary: {len(list(model.modules()))} layers, {n_p} parameters, {n_g} gradients{fs}")

def initialize_weights(model):
    """åœ¨yolo.pyçš„Modelç±»ä¸­çš„initå‡½æ•°è¢«è°ƒç”¨
    ç”¨äºåˆå§‹åŒ–æ¨¡å‹æƒé‡
    """
    for m in model.modules():
        t = type(m)
        if t is nn.Conv2d:   # å¦‚æœæ˜¯äºŒç»´å·ç§¯å°±è·³è¿‡  æˆ–è€…ä½¿ç”¨ä½•å‡¯æ˜åˆå§‹åŒ–
            pass  # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        elif t is nn.BatchNorm2d:  # å¦‚æœæ˜¯BNå±‚ å°±è®¾ç½®ç›¸å…³å‚æ•°: epså’Œmomentum
            m.eps = 1e-3
            m.momentum = 0.03
        elif t in [nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6]:
            # å¦‚æœæ˜¯è¿™å‡ ç±»æ¿€æ´»å‡½æ•° inplaceæ’å€¼å°±èµ‹ä¸ºTrue
            # inplace = True æŒ‡è¿›è¡ŒåŸåœ°æ“ä½œ å¯¹äºä¸Šå±‚ç½‘ç»œä¼ é€’ä¸‹æ¥çš„tensorç›´æ¥è¿›è¡Œä¿®æ”¹ ä¸éœ€è¦å¦å¤–èµ‹å€¼å˜é‡
            # è¿™æ ·å¯ä»¥èŠ‚çœè¿ç®—å†…å­˜ï¼Œä¸ç”¨å¤šå‚¨å­˜å˜é‡
            m.inplace = True

# æ²¡ç”¨åˆ°
def find_modules(model, mclass=nn.Conv2d):
    """
    ç”¨äºæ‰¾åˆ°æ¨¡å‹modelä¸­ç±»å‹æ˜¯mclassçš„å±‚ç»“æ„çš„ç´¢å¼•  Finds layer indices matching module class 'mclass'
    :params model: æ¨¡å‹
    :params mclass: å±‚ç»“æ„ç±»å‹ é»˜è®¤nn.Conv2d
    """
    return [i for i, m in enumerate(model.module_list) if isinstance(m, mclass)]

def sparsity(model):
    """åœ¨pruneä¸­è°ƒç”¨
    ç”¨äºæ±‚æ¨¡å‹modelçš„ç¨€ç–ç¨‹åº¦sparsity   Return global model sparsity
    """
    # åˆå§‹åŒ–æ¨¡å‹çš„æ€»å‚æ•°ä¸ªæ•°a(å‰å‘+åå‘)  æ¨¡å‹å‚æ•°ä¸­å€¼ä¸º0çš„å‚æ•°ä¸ªæ•°b
    a, b = 0., 0.
    # model.parameters()è¿”å›æ¨¡å‹modelçš„å‚æ•° è¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ éœ€è¦ç”¨forå¾ªç¯æˆ–è€…next()æ¥è·å–å‚æ•°
    # forå¾ªç¯å–å‡ºæ¯ä¸€å±‚çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­çš„å‚æ•°
    for p in model.parameters():
        a += p.numel()
        b += (p == 0).sum()
    # b / a å³å¯ä»¥ååº”æ¨¡å‹çš„ç¨€ç–ç¨‹åº¦
    return b / a
def prune(model, amount=0.3):
    """å¯ä»¥ç”¨äºtest.pyå’Œdetect.pyä¸­è¿›è¡Œæ¨¡å‹å‰ªæ
    å¯¹æ¨¡å‹modelè¿›è¡Œå‰ªææ“ä½œ ä»¥å¢åŠ æ¨¡å‹çš„ç¨€ç–æ€§  ä½¿ç”¨pruneå·¥å…·å°†å‚æ•°ç¨€ç–åŒ–
    https://github.com/ultralytics/yolov5/issues/304
    :params model: æ¨¡å‹
    :params amount: éšæœºè£å‰ª(æ€»å‚æ•°é‡ x amount)æ•°é‡çš„å‚æ•°
    """
    import torch.nn.utils.prune as prune  # å¯¼å…¥ç”¨äºå‰ªæçš„å·¥å…·åŒ…
    print('Pruning model... ', end='')
    # æ¨¡å‹çš„è¿­ä»£å™¨ è¿”å›çš„æ˜¯æ‰€æœ‰æ¨¡å—çš„è¿­ä»£å™¨  åŒæ—¶äº§ç”Ÿæ¨¡å—çš„åç§°(name)ä»¥åŠæ¨¡å—æœ¬èº«(m)
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d):
            # å¯¹å½“å‰å±‚ç»“æ„m, éšæœºè£å‰ª(æ€»å‚æ•°é‡ x amount)æ•°é‡çš„æƒé‡(weight)å‚æ•°
            prune.l1_unstructured(m, name='weight', amount=amount)  # prune
            # å½»åº•ç§»é™¤è¢«è£å‰ªçš„çš„æƒé‡å‚æ•°
            prune.remove(m, 'weight')  # make permanent

    # è¾“å‡ºæ¨¡å‹çš„ç¨€ç–åº¦ è°ƒç”¨sparsityå‡½æ•°è®¡ç®—å½“å‰æ¨¡å‹çš„ç¨€ç–åº¦
    print(' %.3g global sparsity' % sparsity(model))

def fuse_conv_and_bn(conv, bn):
    """åœ¨yolo.pyä¸­Modelç±»çš„fuseå‡½æ•°ä¸­è°ƒç”¨
    èåˆå·ç§¯å±‚å’ŒBNå±‚(æµ‹è¯•æ¨ç†ä½¿ç”¨)   Fuse convolution and batchnorm layers
    æ–¹æ³•: å·ç§¯å±‚è¿˜æ˜¯æ­£å¸¸å®šä¹‰, ä½†æ˜¯å·ç§¯å±‚çš„å‚æ•°w,bè¦æ”¹å˜   é€šè¿‡åªæ”¹å˜å·ç§¯å‚æ•°, è¾¾åˆ°CONV+BNçš„æ•ˆæœ
          w = w_bn * w_conv   b = w_bn * b_conv + b_bn   (å¯ä»¥è¯æ˜)
    https://tehnokv.com/posts/fusing-batchnorm-and-conv/
    https://github.com/ultralytics/yolov3/issues/807
    https://zhuanlan.zhihu.com/p/94138640
    :params conv: torchæ”¯æŒçš„å·ç§¯å±‚
    :params bn: torchæ”¯æŒçš„bnå±‚
    """
    fusedconv = nn.Conv2d(conv.in_channels,
                          conv.out_channels,
                          kernel_size=conv.kernel_size,
                          stride=conv.stride,
                          padding=conv.padding,
                          groups=conv.groups,
                          bias=True).requires_grad_(False).to(conv.weight.device)

    # prepare filters
    # w_conv: å·ç§¯å±‚çš„wå‚æ•° ç›´æ¥clone convçš„weightå³å¯
    w_conv = conv.weight.clone().view(conv.out_channels, -1)
    # w_bn: bnå±‚çš„wå‚æ•°(å¯ä»¥è‡ªå·±æ¨åˆ°å…¬å¼)  torch.diag: è¿”å›ä¸€ä¸ªä»¥inputä¸ºå¯¹è§’çº¿å…ƒç´ çš„2D/1D æ–¹é˜µ/å¼ é‡?
    w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))
    # w = w_bn * w_conv      torch.mm: å¯¹ä¸¤ä¸ªçŸ©é˜µç›¸ä¹˜
    fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.shape))

    # prepare spatial bias
    # b_conv: å·ç§¯å±‚çš„bå‚æ•° å¦‚æœä¸ä¸ºNoneå°±ç›´æ¥è¯»å–conv.biaså³å¯
    b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias
    # b_bn: bnå±‚çš„bå‚æ•°(å¯ä»¥è‡ªå·±æ¨åˆ°å…¬å¼)
    b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))
    #  b = w_bn * b_conv + b_bn   (w_bn not forgot)
    fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)

    return fusedconv

def load_classifier(name='resnet101', n=2):
    """åœ¨detect.pyä¸­è°ƒç”¨ è¿›è¡ŒäºŒæ¬¡åˆ†ç±»
    ç”¨äºæ£€æµ‹ç»“æŸåå¯èƒ½éœ€è¦ç¬¬äºŒæ¬¡åˆ†ç±»  ç›´æ¥ä¿®æ”¹torchvisionä¸­çš„é¢„è®­ç»ƒæ¨¡å‹çš„åˆ†ç±»ç±»åˆ«å³å¯
    :params name: åˆ†ç±»æ¨¡å‹åå­— é»˜è®¤resnet101
    :params n: åˆ†ç±»æ¨¡å‹çš„åˆ†ç±»ç±»åˆ«æ•°  éœ€è¦åœ¨åŠ è½½äº†é¢„è®­ç»ƒæ¨¡å‹åå°†modelçš„æœ€åä¸€å±‚çš„ç±»åˆ«æ•°æ”¹ä¸ºn
    """
    # åŠ è½½torchvisionä¸­å·²ç»å†™å¥½çš„pretrainedæ¨¡å‹  reshapeä¸ºnç±»è¾“å‡º
    model = torchvision.models.__dict__[name](pretrained=True)

    # ResNet model properties
    # input_size = [3, 224, 224]
    # input_space = 'RGB'
    # input_range = [0, 1]
    # mean = [0.485, 0.456, 0.406]
    # std = [0.229, 0.224, 0.225]

    # å°†åŠ è½½çš„é¢„è®­ç»ƒæ¨¡å‹çš„æœ€åä¸€å±‚çš„åˆ†ç±»ç±»åˆ«æ•°æ”¹ä¸ºn  Reshape output to n classes
    # æ€»ä½“çš„è¿‡ç¨‹ = å°†fcå±‚çš„æƒé‡å’Œåç½®æ¸…0 + ä¿®æ”¹ç±»åˆ«ä¸ªæ•°ä¸ºn
    filters = model.fc.weight.shape[1]
    model.fc.bias = nn.Parameter(torch.zeros(n), requires_grad=True)
    model.fc.weight = nn.Parameter(torch.zeros(n, filters), requires_grad=True)
    model.fc.out_features = n
    # è¿”å›reshapeåçš„æ¨¡å‹ è¿›è¡ŒäºŒæ¬¡åˆ†ç±»
    return model

def scale_img(img, ratio=1.0, same_shape=False, gs=32):
    """ç”¨äºyolo.pyæ–‡ä»¶ä¸­Modelç±»çš„forward_augmentå‡½æ•°ä¸­
    å®ç°å¯¹å›¾ç‰‡çš„ç¼©æ”¾æ“ä½œ
    :params img: åŸå›¾
    :params ratio: ç¼©æ”¾æ¯”ä¾‹ é»˜è®¤=1.0 åŸå›¾
    :params same_shape: ç¼©æ”¾ä¹‹åå°ºå¯¸æ˜¯å¦æ˜¯è¦æ±‚çš„å¤§å°(å¿…é¡»æ˜¯gs=32çš„å€æ•°)
    :params gs: æœ€å¤§çš„ä¸‹é‡‡æ ·ç‡ 32 æ‰€ä»¥ç¼©æ”¾åçš„å›¾ç‰‡çš„shapeå¿…é¡»æ˜¯gs=32çš„å€æ•°
    """
    # img(16,3,256,416)
    # scales img(bs,3,y,x) by ratio constrained to gs-multiple
    if ratio == 1.0:   # å¦‚æœç¼©æ”¾æ¯”ä¾‹ratioä¸º1.0 ç›´æ¥è¿”å›åŸå›¾
        return img
    else:  # å¦‚æœç¼©æ”¾æ¯”ä¾‹ratioä¸ä¸º1.0 åˆ™å¼€å§‹æ ¹æ®ç¼©æ”¾æ¯”ä¾‹ratioè¿›è¡Œç¼©æ”¾
        # h, w: åŸå›¾çš„é«˜å’Œå®½
        h, w = img.shape[2:]
        # s: æ”¾ç¼©åå›¾ç‰‡çš„æ–°å°ºå¯¸  new size
        s = (int(h * ratio), int(w * ratio))
        # ç›´æ¥ä½¿ç”¨torchè‡ªå¸¦çš„F.interpolate(ä¸Šé‡‡æ ·ä¸‹é‡‡æ ·å‡½æ•°)æ’å€¼å‡½æ•°è¿›è¡Œresize
        # F.interpolate: å¯ä»¥ç»™å®šsizeæˆ–è€…scale_factoræ¥è¿›è¡Œä¸Šä¸‹é‡‡æ ·
        #                mode='bilinear': åŒçº¿æ€§æ’å€¼  nearest:æœ€è¿‘é‚»
        #                align_corner: æ˜¯å¦å¯¹é½ input å’Œ output çš„è§’ç‚¹åƒç´ (corner pixels)
        img = F.interpolate(img, size=s, mode='bilinear', align_corners=False)
        if not same_shape:
            # ç¼©æ”¾ä¹‹åè¦æ˜¯å°ºå¯¸å’Œè¦æ±‚çš„å¤§å°(å¿…é¡»æ˜¯gs=32çš„å€æ•°)ä¸åŒ å†å¯¹å…¶ä¸ç›¸äº¤çš„éƒ¨åˆ†è¿›è¡Œpad
            # è€Œpadçš„å€¼å°±æ˜¯imagenetçš„mean
            # Math.ceil(): å‘ä¸Šå–æ•´  è¿™é‡Œé™¤ä»¥gså‘ä¸Šå–æ•´å†ä¹˜ä»¥gsæ˜¯ä¸ºäº†ä¿è¯hã€wéƒ½æ˜¯gsçš„å€æ•°
            h, w = [math.ceil(x * ratio / gs) * gs for x in (h, w)]
        # pad img shape to gsçš„å€æ•° å¡«å……å€¼ä¸º imagenet mean
        return F.pad(img, [0, w - s[1], 0, h - s[0]], value=0.447)

def de_parallel(model):
    """ç”¨åœ¨train.pyä¸­, ç”¨äºåŠ è½½å’Œä¿å­˜æ¨¡å‹(å‚æ•°)
    åˆ¤æ–­å•å¡è¿˜æ˜¯å¤šå¡(èƒ½å¦å¹¶è¡Œ)  å¤šå¡è¿”å›model.module  å•å¡è¿”å›model
    """
    # De-parallelize a model: returns single-GPU model if model is of type DP or DDP
    # å¦‚æœmodelæ”¯æŒå¹¶è¡Œ(å¤šå¡)å°±è¿”å›model.module  ä¸æ”¯æŒå¹¶è¡Œå°±è¿”å›model
    # ç”¨åœ¨tainä¸­ä¿å­˜æ¨¡å‹ å› ä¸ºå¤šå¡è®­ç»ƒçš„æ—¶å€™ç›´æ¥ç”¨model.state_dict()è¿›è¡Œä¿å­˜çš„æ¨¡å‹, æ¯ä¸ªå±‚å‚æ•°çš„åç§°å‰é¢ä¼šåŠ ä¸Šmodule,
    # è¿™æ—¶å€™å†ç”¨å•å¡(gpu) model_dictåŠ è½½model.state_dict()å‚æ•°æ—¶ä¼šå‡ºç°åç§°ä¸åŒ¹é…çš„æƒ…å†µ,
    # å› æ­¤å¤šå¡ä¿å­˜æ¨¡å‹æ—¶æ³¨æ„ä½¿ç”¨model.module.state_dict() å³è¿”å›model.module  å•å¡è¿”å›modelå³å¯
    return model.module if is_parallel(model) else model

def is_parallel(model):
    """åœ¨ModelEMAç±»ä¸­è°ƒç”¨
    ç”¨äºåˆ¤æ–­æ¨¡å‹æ˜¯å¦æ”¯æŒå¹¶è¡Œ  Returns True if model is of type DP or DDP
    """
    return type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)
def copy_attr(a, b, include=(), exclude=()):
    """åœ¨ModelEMAå‡½æ•°å’Œyolo.pyä¸­Modelç±»çš„autoshapeå‡½æ•°ä¸­è°ƒç”¨
    å¤åˆ¶bçš„å±æ€§(è¿™ä¸ªå±æ€§å¿…é¡»åœ¨includeä¸­è€Œä¸åœ¨excludeä¸­)ç»™a
    :params a: å¯¹è±¡a(å¾…èµ‹å€¼)
    :params b: å¯¹è±¡b(èµ‹å€¼)
    :params include: å¯ä»¥èµ‹å€¼çš„å±æ€§
    :params exclude: ä¸èƒ½èµ‹å€¼çš„å±æ€§
    """
    # Copy attributes from b to a, options to only include [...] and to exclude [...]
    # __dict__è¿”å›ä¸€ä¸ªç±»çš„å®ä¾‹çš„å±æ€§å’Œå¯¹åº”å–å€¼çš„å­—å…¸
    for k, v in b.__dict__.items():
        if (len(include) and k not in include) or k.startswith('_') or k in exclude:
            continue
        else:
            # å°†å¯¹è±¡bçš„å±æ€§kèµ‹å€¼ç»™a
            setattr(a, k, v)
class ModelEMA:
    """ç”¨åœ¨train.pyä¸­çš„test.runï¼ˆæµ‹è¯•ï¼‰é˜¶æ®µ
    æ¨¡å‹çš„æŒ‡æ•°åŠ æƒå¹³å‡æ–¹æ³•(Model Exponential Moving Average)
    æ˜¯ä¸€ç§ç»™äºˆè¿‘æœŸæ•°æ®æ›´é«˜æƒé‡çš„å¹³å‡æ–¹æ³• åˆ©ç”¨æ»‘åŠ¨å¹³å‡çš„å‚æ•°æ¥æé«˜æ¨¡å‹åœ¨æµ‹è¯•æ•°æ®ä¸Šçš„å¥å£®æ€§/é²æ£’æ€§ ä¸€èˆ¬ç”¨äºæµ‹è¯•é›†
    https://www.bilibili.com/video/BV1FT4y1E74V?p=63
    https://www.cnblogs.com/wuliytTaotao/p/9479958.html
    https://zhuanlan.zhihu.com/p/68748778
    https://zhuanlan.zhihu.com/p/32335746
    https://github.com/ultralytics/yolov5/issues/608
    https://github.com/rwightman/pytorch-image-models/blob/master/timm/utils/model_ema.py
    """
    def __init__(self, model, decay=0.9999, updates=0):
        """train.py
        model:
        decay: è¡°å‡å‡½æ•°å‚æ•°
               é»˜è®¤0.9999 è€ƒè™‘è¿‡å»10000æ¬¡çš„çœŸå®å€¼
        updates: emaæ›´æ–°æ¬¡æ•°
        """
        # åˆ›å»ºemaæ¨¡å‹  Create EMA
        self.ema = deepcopy(model.module if is_parallel(model) else model).eval()  # FP32 EMA
        # if next(model.parameters()).device.type != 'cpu':
        #     self.ema.half()  # FP16 EMA
        self.updates = updates  # emaæ›´æ–°æ¬¡æ•° number of EMA updates
        # self.decay: è¡°å‡å‡½æ•° è¾“å…¥å˜é‡ä¸ºx  decay exponential ramp (to help early epochs)
        self.decay = lambda x: decay * (1 - math.exp(-x / 2000))
        # æ‰€æœ‰å‚æ•°å–æ¶ˆè®¾ç½®æ¢¯åº¦(æµ‹è¯•  model.val)
        for p in self.ema.parameters():
            p.requires_grad_(False)

    def update(self, model):
        # æ›´æ–°emaçš„å‚æ•°  Update EMA parameters
        with torch.no_grad():
            self.updates += 1  # emaæ›´æ–°æ¬¡æ•° + 1
            d = self.decay(self.updates)  # éšç€æ›´æ–°æ¬¡æ•° æ›´æ–°å‚æ•°è´å¡”(d)

            # msd: æ¨¡å‹é…ç½®çš„å­—å…¸ model state_dict  msdä¸­çš„æ•°æ®ä¿æŒä¸å˜ ç”¨äºè®­ç»ƒ
            msd = model.module.state_dict() if is_parallel(model) else model.state_dict()
            # éå†æ¨¡å‹é…ç½®å­—å…¸ å¦‚: k=linear.bias  v=[0.32, 0.25]  emaä¸­çš„æ•°æ®å‘ç”Ÿæ”¹å˜ ç”¨äºæµ‹è¯•
            for k, v in self.ema.state_dict().items():
                # è¿™é‡Œå¾—åˆ°çš„v: é¢„æµ‹å€¼
                if v.dtype.is_floating_point:
                    v *= d    # å…¬å¼å·¦è¾¹  decay * shadow_variable
                    # .detach() ä½¿å¯¹åº”çš„Variablesä¸ç½‘ç»œéš”å¼€è€Œä¸å‚ä¸æ¢¯åº¦æ›´æ–°
                    v += (1. - d) * msd[k].detach()  # å…¬å¼å³è¾¹  (1âˆ’decay) * variable

    def update_attr(self, model, include=(), exclude=('process_group', 'reducer')):
        # è°ƒç”¨ä¸Šé¢çš„copy_attrå‡½æ•° ä»modelä¸­å¤åˆ¶ç›¸å…³å±æ€§å€¼åˆ°self.emaä¸­
        copy_attr(self.ema, model, include, exclude)
